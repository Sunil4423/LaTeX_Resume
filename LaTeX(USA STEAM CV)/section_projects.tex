% YAAC Another Awesome CV LaTeX Template
%
% This template has been downloaded from:
% https://github.com/darwiin/yaac-another-awesome-cv
%
% Author:
% Christophe Roger
%
% Template license:
% CC BY-SA 4.0 (https://creativecommons.org/licenses/by-sa/4.0/)

%Section compétences

\renewcommand{\baselinestretch}{1.3}
\sectionTitle{Project Details   }{}

\begin{keywords}
		\keywordsentry{Project 1:}
		{MR SAM }
%		\keywordsentry{Client:}
%		{Lowell Financial, UK }
		\keywordsentry{Technologies Used:}
		{Python, Machine Learning, Matplotlib, Seaborn.}
	%	\keywordsentry{Big Data Technologies: }{\fontfamily{qtm}\selectfont
	%	{ Spark (Python), Spark SQL, Databricks }}
	%	\keywordsentry{Visualization tools:}{\fontfamily{qtm}\selectfont
	%	{Tableau, MS Excel}}
		%\keywordsentry{Systèmes d'exploitation}{Mac OS X, Windows Server, Windows 7, Linux Redhat, Linux Centos}
		%\keywordsentry{Autres}{architecture SOA, technologies RFID, NFC et code barre 1D/2D}
\end{keywords}
\begin{experiences}
  \experience
    { }   {Responsibilities:}{}{}
    {} {
                      \begin{itemize}
                        \item Objective is to identify/predict component/subcomponent Frequency Break down with maximum possible lead time.                          
                        \item Predicted subset of RF Seekear failures with 95\text{\%}  accuracy using vibration data.                                        
                        \item Prescriptive maintenance on IMU, GPS cards, Transmitter health using efficacy, RPM, Frequency and Temperature,  normalization techniques.
                        
                        \item Setting up end to end training/Testing and scoring pipeline for various models using Random Forest,etc.
                        
                        \item Story telling with Data by extracting Pattern form the sensor  Data.
                        
                    %    \item Created Data cleansing framework using Databricks notebooks in Pyspark.
                        
                     %   \item Managed indexes and optimized queries by using execution plan.
                        
                      %  \item Built DB design like creating tables, Indexes and writing Stored procedures, Views, \t Functions and Joins. 
                      \end{itemize}
                    }


\end{experiences}


\renewcommand{\baselinestretch}{1.3}
%\sectionTitle{Project Details   }{}

\begin{keywords}
		\keywordsentry{Project 2:}
		{IAM Mark-2 (Integrated avionics module )
  }
	%	\keywordsentry{Client:}
	%	{Lowell Financial, UK }
		\keywordsentry{Technologies Used:}
		{CNN, VGG16, Keras, Tensorflow, Python.}
	%	\keywordsentry{Big Data Technologies: }{\fontfamily{qtm}\selectfont
	%	{ Spark (Python), Spark SQL, Databricks }}
	%	\keywordsentry{Visualization tools:}{\fontfamily{qtm}\selectfont
	%	{Tableau, MS Excel}}
		%\keywordsentry{Systèmes d'exploitation}{Mac OS X, Windows Server, Windows 7, Linux Redhat, Linux Centos}
		%\keywordsentry{Autres}{architecture SOA, technologies RFID, NFC et code barre 1D/2D}
\end{keywords}
\begin{experiences}
  \experience
    { }   {Responsibilities:}{}{}
    {} {
                      \begin{itemize}
                        \item Worked on identifying and counting the number of identical objects in a given image.
                          
                        \item Framed the problems as object detection and model was developed by using  \t TensorFlow, Keras, and Pre-Trained (VGG16) model.                    
                        \item Optimized the model by trying out various feature extractors, optimizers and loss function. Improved the  performance at detecting object by further tuning the \t parameters of the model.
                        
                       % \item Experience in data extraction from S3 and worked on sql scripts as per the requirements.
                        
                       % \item Devloped PySpark scripts based on SAS Files understanding and modifying as per client requirement.
                        
                       % \item Created Data cleansing framework using Databricks notebooks in Pyspark.
                        
                       % \item Managed indexes and optimized queries by using execution plan.
                        
                        %\item Built DB design like creating tables, Indexes and writing Stored procedures, Views, Functions and Joins. 
                      \end{itemize}
                    }


\end{experiences}

%\renewcommand{\baselinestretch}{1.5}
%\sectionTitle{Project Details   }{}

%\begin{keywords}
	%	\keywordsentry{Project 3:}
	%	{Sempra}
	%	\keywordsentry{Client:}
	%	{Lowell Financial, UK }
	%	\keywordsentry{Technologies Used:}
	%	{ PySpark, Linux, Putty, WinSCP, MS-SQL, Dkron   }
	%	\keywordsentry{Big Data Technologies: }{\fontfamily{qtm}\selectfont
	%	{ Spark (Python), Spark SQL, Databricks }}
	%	\keywordsentry{Visualization tools:}{\fontfamily{qtm}\selectfont
	%	{Tableau, MS Excel}}
		%\keywordsentry{Systèmes d'exploitation}{Mac OS X, Windows Server, Windows 7, Linux Redhat, Linux Centos}
		%\keywordsentry{Autres}{architecture SOA, technologies RFID, NFC et code barre 1D/2D}
%\end{keywords}
%\begin{experiences}
 % \experience
  %  { }   {Responsibilities:}{}{}
 %   {} {
                   %   \begin{itemize}
                     %   \item Designed and developed Pyspark script to pull data from RDBMS systems and files.
                   %     \item Worked on SQL to Pyspark conversations.                    
                    %    \item Involved in unit testing as per the requirements.
                        
                 %       \item Scheduled and executed Pyspark scripts using Dkron jobs.
.
                        
                       % \item Devloped PySpark scripts based on SAS Files understanding and modifying as per client requirement.
                        
                       % \item Created Data cleansing framework using Databricks notebooks in Pyspark.
                        
                       % \item Managed indexes and optimized queries by using execution plan.
                        
                        %\item Built DB design like creating tables, Indexes and writing Stored procedures, Views, Functions and Joins. 
   %                   \end{itemize}
  %                  }
 %                   {}


%\end{experiences}\\